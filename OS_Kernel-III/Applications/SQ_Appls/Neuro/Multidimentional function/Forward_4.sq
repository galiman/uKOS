
//------------------------------------------------------------------------
// Author:	Franzi Edo.	The 2001-02-25
// Modifs: 
//
// SVN:
// $Author:: efr               $:  Author of last commit
// $Rev:: 161                  $:  Revision of last commit
// $Date:: 2017-06-15 15:01:25#$:  Date of last commit		
//
// Project:	uKOS
// Goal:	Feed forward a 5 layers (3 hidden) full connected networks
//
//			i  = inputs vector
//			W  = weght matrix
//			Wn = weght (next layer) matrix
//			p  = activity (potential) vector
//			o  = output vector
//			oe = output expected vector
//			f  = non linear function (tanh or sigmoid)
//			df = non linear derivative function (tanh or sigmoid)
//			eq = last layer quadratic error
//			e  = layer error
//			en = next layer error
//			e  = layer error
//			d  = delta matrix
//
//			Feedforward equations:
//
//			p = W . i
//			o = f(p)
//
//   (c) 1992-2017, Franzi Edo.
//   --------------------------
//                                              __ ______  _____
//   Franzi Edo.                         __  __/ //_/ __ \/ ___/
//   5-Route de Cheseaux                / / / / ,< / / / /\__ \
//   CH 1400 Cheseaux-NorÃ©az           / /_/ / /| / /_/ /___/ /
//                                     \__,_/_/ |_\____//____/
//   edo.franzi@ukos.ch
//
//   This program is free software: you can redistribute it and/or modify
//   it under the terms of the GNU Affero General Public License as published by
//   the Free Software Foundation, either version 3 of the License, or
//   (at your option) any later version.
//
//   This program is distributed in the hope that it will be useful,
//   but WITHOUT ANY WARRANTY; without even the implied warranty of
//   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
//   GNU Affero General Public License for more details.
//
//   You should have received a copy of the GNU Affero General Public License
//   along with this program. If not, see <http://www.gnu.org/licenses/>.
//
//------------------------------------------------------------------------

// Network description
// -------------------

// Layer 1 (input)

variable L1_input				// Inputs of the layer L1
variable L1_activity			// Activity of the layer L1
variable L1_output				// Outputs of the layer L1
variable L1_weight				// Weights of the layer L1

// Layer 2 (hidden)

variable L2_input				// Inputs of the layer L2
variable L2_activity			// Activity of the layer L2
variable L2_output				// Outputs of the layer L2
variable L2_weight				// Weights of the layer L2

// Layer 3 (hidden)

variable L3_input				// Inputs of the layer L3
variable L3_activity			// Activity of the layer L3
variable L3_output				// Outputs of the layer L3
variable L3_weight				// Weights of the layer L3

// Layer 4 (output)

variable L4_input				// Inputs of the layer L4
variable L4_activity			// Activity of the layer L4
variable L4_output				// Outputs of the layer L4
variable L4_weight				// Weights of the layer L4

// Databases

variable DB_input_L				// Inputs vector (Learning)
variable DB_expected_L			// Expected vector (Learning)
variable DB_input_V				// Inputs vector (Verifying)
variable DB_expected_V			// Expected vector (Verifying)

// NN

variable NN_display				// Output for display (1: output, 2: expected))
variable NN_noise				// Noise rate

// Prototypes
// ----------

terminate	terminate()

init (L1_input, L1_weight, L1_activity, L1_output, ...
	  L2_input, L2_weight, L2_activity, L2_output, ...
	  L3_input, L3_weight, L3_activity, L3_output, ...
	  L4_input, L4_weight, L4_activity, L4_output, ...
	  DB_input_L, DB_expected_L, DB_input_V, DB_expected_V, NN_display, NN_noise) = init

idle (NN_display) = feedForward(L1_input, L1_weight, L1_activity, L1_output, ...
								L2_input, L2_weight, L2_activity, L2_output, ...
								L3_input, L3_weight, L3_activity, L3_output, ...
								L4_input, L4_weight, L4_activity, L4_output, ...
								DB_input_L, DB_expected_L, DB_input_V, DB_expected_V, NN_display, NN_noise);

figure "Controls"
	draw drawSlider(NN_noise)
	mousedrag(NN_noise) = dragSlider(NN_noise, _id, _nb, _ix, _x1)

figure "Function output - expected"
	draw output(NN_display)

functions
{@

define	  KTRUE			= -1;			// True
define	  KFALSE		= 0;			// False

// Network description & Database format
// =====================================
//
// The file format of the database is the following one:
//
// in1_M	in_2	in_3	in_n	out_1	ont_2	out_n
//
// in1_M	Monotonic input (-1..+1) distributed over all the database. This input is not modified by a random noise
// in_2..n	Reduced end centered input data (-1..+1). These inputs could be modified by a random noise
// out_1..n	Reduced end centered expected output (-1..+1)

// Database format
// ---------------

define    KMONOTONIC	= KFALSE;		// The in1_M is monotonic. Do not add noise to this input
define    KPOSIN1		= 1;			// Position of the in_1..
define    KPOSINN		= 10;			// Position of the in_n..
define    KPOSOUT1		= 11;			// Position of the out_1..
define    KPOSOUTN		= 12;			// Position of the out_n..

// Network description
// -------------------

define    KL1NBIN		= 10;			// Number of inputs (L1)
define    KL1NBOUT 		= 65;			// Number of output (L1)
define    KL2NBIN		= KL1NBOUT;		// Number of inputs (L2)
define    KL2NBOUT 		= 65;			// Number of output (L2)
define    KL3NBIN		= KL2NBOUT;		// Number of inputs (L3)
define    KL3NBOUT 		= 65;			// Number of output (L3)
define    KL4NBIN		= KL3NBOUT;		// Number of inputs (L4)
define    KL4NBOUT 		= 2;			// Number of output (L4)
define    KINNOISE		= 0/100;		// Add some noise to the input vector
define	  KNBDBSAMPLES	= 333;			// Number of samples of the BD

// Terminate
// ---------

function terminate();

// Initialisations
// ---------------

// Load the training and the associated weight sets

function (input_l1, weight_l1, activity_l1, output_l1, ...
		  input_l2, weight_l2, activity_l2, output_l2, ...
		  input_l3, weight_l3, activity_l3, output_l3, ...
		  input_l4, weight_l4, activity_l4, output_l4, ...
		  input_l, expected_l, input_v, expected_v, display, noise) = init

	subplots(['Function output - expected\nControls']);

    noise = KINNOISE;

// Initialise the network

	input_l1  				= zeros(KL1NBIN+1, 1);
	input_l1(KL1NBIN+1, 1)	= -1;	
	activity_l1				= zeros(KL1NBOUT, 1);
	output_l1				= zeros(KL1NBOUT, 1);
	weight_l1				= zeros(size(output_l1, 1), size(input_l1, 1));

	input_l2 				= zeros(KL2NBIN+1, 1);
	input_l2(KL2NBIN+1, 1)	= -1;	
	activity_l2				= zeros(KL2NBOUT, 1);
	output_l2 				= zeros(KL2NBOUT, 1);
	weight_l2 				= zeros(size(output_l2, 1), size(input_l2, 1));

	input_l3 				= zeros(KL3NBIN+1, 1);
	input_l3(KL3NBIN+1, 1)	= -1;	
	activity_l3				= zeros(KL3NBOUT, 1);
	output_l3 				= zeros(KL3NBOUT, 1);
	weight_l3 				= zeros(size(output_l3, 1), size(input_l3, 1));

	input_l4 				= zeros(KL4NBIN+1, 1);
	input_l4(KL4NBIN+1, 1)	= -1;	
	activity_l4				= zeros(KL4NBOUT, 1);
	output_l4 				= zeros(KL4NBOUT, 1);
	weight_l4 				= zeros(size(output_l4, 1), size(input_l4, 1));

	display					= zeros(2, KL4NBOUT, KNBDBSAMPLES);

// Read the Learning & the Verifying data sets (the data have to be reduced and centered)
// Open the Database files

	path = getfile('Training & verifying Data & weight sets:');
	if isempty(path)
		return;
	end

// Read the Learning, the Verifying data and the weight sets

	(dir, filename, ext) = fileparts(path);
	fd_l = fopen([dir, 'DB_L_file', '.txt'], 'rt');
	fd_v = fopen([dir, 'DB_V_file', '.txt'], 'rt');
	fd_W = fopen([dir, 'WW_file',   '.txt'], 'rt');

	for i = 1:KNBDBSAMPLES
		data_l = fscanf(fd_l, '%f');
		data_v = fscanf(fd_v, '%f');

		input_l(i, KPOSIN1:KPOSINN)   				     = data_l(KPOSIN1:KPOSINN);
		input_v(i, KPOSIN1:KPOSINN)   				     = data_v(KPOSIN1:KPOSINN);
		expected_l(i, KPOSOUT1-KPOSINN:KPOSOUTN-KPOSINN) = data_l(KPOSOUT1:KPOSOUTN);
		expected_v(i, KPOSOUT1-KPOSINN:KPOSOUTN-KPOSINN) = data_v(KPOSOUT1:KPOSOUTN);
	end

	(weight_l1) = _readWeight(fd_W, weight_l1);
	(weight_l2) = _readWeight(fd_W, weight_l2);
	(weight_l3) = _readWeight(fd_W, weight_l3);
	(weight_l4) = _readWeight(fd_W, weight_l4);

// Rearrange the vectors in order to be compatible with the NN structure

	input_l    = input_l';
	input_v    = input_v';
	expected_l = expected_l';
	expected_v = expected_v';

	fclose(fd_l);
	fclose(fd_v);
	fclose(fd_W);

// - Read the weight sets

function (weight) = _readWeight(fd, weight);
	for i = 1:size(weight, 1)
		weight(i, :) = fscanf(fd,'%f');
	end
	fscanf(fd,'%f');

// Compute ...
// ===========

// feedForward loop
// ----------------

// Compute the network (forward propagation)

function (display) = feedForward(input_l1, weight_l1, activity_l1, output_l1, ...
								 input_l2, weight_l2, activity_l2, output_l2, ...
								 input_l3, weight_l3, activity_l3, output_l3, ...
								 input_l4, weight_l4, activity_l4, output_l4, ...
								 input_l, expected_l, input_v, expected_v, display, noise);

	for i = 1:KNBDBSAMPLES

// Compute the network (forward propagation)
// Add some noise to the inputs (only the inputs KPOSIN1+1:KPOSINN)
//    if KMONOTONIC == KTRUE,  then noise on inputs in_2..in_n
//    if KMONOTONIC == KFALSE, then noise on inputs in_1M..in_n

		if KMONOTONIC == KTRUE
			input(1:KPOSIN1)         = input_v(1:KPOSIN1, i);
			input(1+KPOSIN1:KPOSINN) = input_v(1+KPOSIN1:KPOSINN, i) + (rand(KPOSINN-(1+KPOSIN1)+1, 1) - 0.5) * noise;
		else
			input(KPOSIN1:KPOSINN)   = input_v(  KPOSIN1:KPOSINN, i) + (rand(KPOSINN-KPOSIN1+1,     1) - 0.5) * noise;
		end

		(input_l1, output_l1, activity_l1, ...
		 input_l2, output_l2, activity_l2, ...
		 input_l3, output_l3, activity_l3, ...
		 input_l4, output_l4, activity_l4) = mlp_forwardPropagation(input, ...
														 			input_l1, weight_l1, output_l1, ...
														 			input_l2, weight_l2, output_l2, ...
														 			input_l3, weight_l3, output_l3, ...
														 			input_l4, weight_l4, output_l4);

		display(1, :, i) = output_l4;
		display(2, :, i) = expected_v(:, i);
	end

// Sliders
// -------

function drawSlider(noise);
	slider(sprintf('Noise: %.2g %   \n', noise*100), [noise], [0, 1], '-', '', id=1);

function (noise) = dragSlider(noise, id, nb, ix, x1);
    if isempty(nb)
		cancel;
    end
	switch id
		case 1
			noise = x1;
	end

// Display the outputs
// --------------------

function output(display)
	scale([1, KNBDBSAMPLES, -1, 1]);
	x = (1:KNBDBSAMPLES);

// y1x --> NN output
// y2x --> DB expected output

	y11 = squeeze(display(1, 1, :))';
	y12 = squeeze(display(1, 2, :))';
	y21 = squeeze(display(2, 1, :))';
	y22 = squeeze(display(2, 2, :))';
	plot(x, y11, 'g');
	plot(x, y21, 'm');
	plot(x, y12, 'r');
	plot(x, y22, 'b');

// MLP specific routines
// =====================

// Compute the full MLP forward propagation
// ----------------------------------------

function (input_l1, output_l1, activity_l1, ...
		  input_l2, output_l2, activity_l2, ...
		  input_l3, output_l3, activity_l3, ...
		  input_l4, output_l4, activity_l4) = mlp_forwardPropagation(data, ...
													 				 input_l1, weight_l1, output_l1, ...
													 				 input_l2, weight_l2, output_l2, ...
													 				 input_l3, weight_l3, output_l3, ...
													 				 input_l4, weight_l4, output_l4);

	(input_l1, output_l1, activity_l1) = _layer(input_l1, weight_l1, data);
	(input_l2, output_l2, activity_l2) = _layer(input_l2, weight_l2, output_l1);
	(input_l3, output_l3, activity_l3) = _layer(input_l3, weight_l3, output_l2);
	(input_l4, output_l4, activity_l4) = _layer(input_l4, weight_l4, output_l3);

// - Compute the a NN layer

function (input, output, activity) = _layer(input, weight, data);
	input(1:size(input, 1)-1, 1) = data;
	activity                     = weight * input;
	output                       = _neuron_A(activity);

// - Compute the neuron function y = tanh(x)

function (output) = _neuron_A(activity);
	output = tanh(activity);

@}
